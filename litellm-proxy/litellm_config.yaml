# =============================================================================
# LITELLM PROXY CONFIGURATION
# Models synced with config/defaults.json
# Updated: December 2025
# =============================================================================

model_list:

  # ===========================================================================
  # OPENAI CHAT MODELS - GPT-4.1 Family
  # ===========================================================================
  - model_name: gpt-4.1
    litellm_params:
      model: gpt-4.1
      api_key: os.environ/OPENAI_API_KEY
    model_info:
      supports_function_calling: true
      max_input_tokens: 1000000

  - model_name: gpt-4.1-mini
    litellm_params:
      model: gpt-4.1-mini
      api_key: os.environ/OPENAI_API_KEY
    model_info:
      supports_function_calling: true
      max_input_tokens: 1000000

  - model_name: gpt-4.1-nano
    litellm_params:
      model: gpt-4.1-nano
      api_key: os.environ/OPENAI_API_KEY
    model_info:
      supports_function_calling: true
      max_input_tokens: 1000000

  # ===========================================================================
  # MISTRAL AI MODELS
  # ===========================================================================
  - model_name: mistral-large-3
    litellm_params:
      model: mistral/mistral-large-latest
      api_key: os.environ/MISTRAL_API_KEY
    model_info:
      supports_function_calling: true
      max_input_tokens: 256000

  - model_name: mistral-small-3.2
    litellm_params:
      model: mistral/mistral-small-2506
      api_key: os.environ/MISTRAL_API_KEY
    model_info:
      supports_function_calling: true

  - model_name: ministral-8b
    litellm_params:
      model: mistral/ministral-8b-latest
      api_key: os.environ/MISTRAL_API_KEY
    model_info:
      supports_function_calling: true

  # ===========================================================================
  # GOOGLE GEMINI MODELS
  # ===========================================================================
  - model_name: gemini-2.5-pro
    litellm_params:
      model: gemini/gemini-2.5-pro
      api_key: os.environ/GEMINI_API_KEY
    model_info:
      supports_function_calling: true
      max_input_tokens: 1000000

  - model_name: gemini-2.5-flash
    litellm_params:
      model: gemini/gemini-2.5-flash
      api_key: os.environ/GEMINI_API_KEY
    model_info:
      supports_function_calling: true
      max_input_tokens: 1000000

  - model_name: gemini-2.5-flash-lite
    litellm_params:
      model: gemini/gemini-2.5-flash-lite
      api_key: os.environ/GEMINI_API_KEY
    model_info:
      supports_function_calling: true
      max_input_tokens: 1000000

  # ===========================================================================
  # OLLAMA LOCAL MODELS
  # ===========================================================================
  - model_name: ollama-llama3.2
    litellm_params:
      model: ollama/llama3.2
      api_base: os.environ/OLLAMA_API_BASE
    model_info:
      supports_function_calling: true

  - model_name: ollama-qwen2.5
    litellm_params:
      model: ollama/qwen2.5
      api_base: os.environ/OLLAMA_API_BASE
    model_info:
      supports_function_calling: true

  - model_name: ollama-mistral
    litellm_params:
      model: ollama/mistral
      api_base: os.environ/OLLAMA_API_BASE
    model_info:
      supports_function_calling: true

  - model_name: ollama-phi4
    litellm_params:
      model: ollama/phi4
      api_base: os.environ/OLLAMA_API_BASE
    model_info:
      supports_function_calling: false

  # ===========================================================================
  # EMBEDDING MODELS
  # ===========================================================================
  - model_name: text-embedding-3-large
    litellm_params:
      model: text-embedding-3-large
      api_key: os.environ/OPENAI_API_KEY

  - model_name: ollama-mxbai-embed
    litellm_params:
      model: ollama/mxbai-embed-large
      api_base: os.environ/OLLAMA_API_BASE

  # ===========================================================================
  # AUDIO/TRANSCRIPTION MODELS
  # ===========================================================================
  - model_name: whisper-1
    litellm_params:
      model: whisper-1
      api_key: os.environ/OPENAI_API_KEY

  - model_name: voxtral-mini
    litellm_params:
      model: mistral/voxtral-mini-latest
      api_key: os.environ/MISTRAL_API_KEY

# =============================================================================
# LITELLM SETTINGS
# =============================================================================

litellm_settings:
  drop_params: true
  request_timeout: 120

# =============================================================================
# GENERAL SETTINGS
# =============================================================================

general_settings:
  master_key: os.environ/LITELLM_MASTER_KEY
  # database_url: os.environ/LITELLM_DATABASE_URL
  disable_spend_logs: true
  store_model_in_db: false
